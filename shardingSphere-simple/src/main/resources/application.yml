logging:
  level:
    com.study: debug

spring:
  application:
    name: shardingSphere-simple

  shardingsphere:
    # 将运行模式配置为Standalone单机模式（Cluster：集群模式）
    mode:
      type: Standalone
      repository:
        type: JDBC
    # 配置多个数据源
    props:
      # 日志显示具体的SQL
      sql-show: true
    datasource:
#      真实数据源名称
      names: ds0,ds1
#      druid数据库连接池配置
      common: &common
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.jdbc.Driver
        time-between-eviction-runs-millis: 60000
        min-evictable-idle-time-millis: 300000
        max-active: 500
        initial-size: 3
        min-idle: 3
        max-wait: 60000
        remove-abandoned: true
        remove-abandoned-timeout: 300
        log-abandoned: true
      # 配置第一个数据源
      ds0:
#        引用common配置
        <<: *common
        driver-class-name: com.mysql.jdbc.Driver
        url: jdbc:mysql://localhost:3306/db_sharding_01?useUnicode=true&useSSL=false&characterEncoding=utf8
        username: root
        password: 123456

      # 配置第二个数据源
      ds1:
        # 引用common配置
        <<: *common
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.jdbc.Driver
        url: jdbc:mysql://localhost:3306/db_sharding_02?useUnicode=true&useSSL=false&characterEncoding=utf8
        username: root
        password: 123456
    rules:
      sharding:
        # 配置所有分片表
        tables:
          # 首先配置商品表的分片策略
          shoping:
            # 声明商品表所在的真实数据节点
#            actual-data-nodes: ds0.shoping_00,ds0.shoping_01,ds1.shoping_00,ds1.shoping_01
#            inline表达式，使用笛卡尔积算法生成结果：ds0.shoping_00,ds0.shoping_01,ds1.shoping_00,ds1.shoping_01
            actual-data-nodes: ds$->{0..1}.shoping_0$->{0..1}
            # 配置shoping表的主键生成策略
            key-generate-strategy:
              # 声明主键为shoping_id
              column: shoping_id
              # 同样指向global-id-snowflake这个具体的主键生成策略
              key-generator-name: global-id-snowflake
            # 配置分库规则
            database-strategy:
              standard:
                # 配置路由键为shoping_id（数据库中的列名）
                sharding-column: shoping_id
                # 配置分片算法（需要配置一个名词，通过别名指向具体的策略）
                sharding-algorithm-name: key-int-mod
            # 配置分表规则
            table-strategy:
              standard:
                # 配置分表的路由键：商品名称
                sharding-column: shoping_name
                sharding-algorithm-name: key-hash-mod

          # 订单分库分表策略
          order_tab:
            # 真实表
            actual-data-nodes: ds$->{0..1}.order_tab
            # 分库策略
            database-strategy:
              # 标准分库策略
              standard:
                # 分库路由key
                sharding-column: order_id
                # 分片算法 name
                sharding-algorithm-name: key-int-mod
            # 主键生成策略
            key-generate-strategy:
              # 主键
              column: order_id
              # 生成策略name
              key-generator-name: global-id-snowflake

          order_info:
            actual-data-nodes: ds$->{0..1}.order_info
            database-strategy:
              standard:
                sharding-column: order_id
                sharding-algorithm-name: key-int-mod
            key-generate-strategy:
              column: order_info_id
              key-generator-name: global-id-snowflake

          user_info:
            actual-data-nodes: ds$->{0..1}.user_info
            key-generate-strategy:
              column: user_id
              key-generator-name: global-id-snowflake

        sharding-algorithms:
#          # 配置前面的分库算法
#          key-int-mod:
#            # 声明是 INLINE 简单类型的分片
#            type: INLINE
#            props:
#              # 选择对shoping_id做取模运算
#              algorithm-expression: ds$->{shoping_id % 2}
          # shardingSphere自带的取模算法
          key-int-mod:
            type: MOD
            props:
              # 声明分库的节点数量
              sharding-count: 2
          key-hash-mod:
            # 配置哈希取模的分表算法
            type: HASH_MOD
            props:
              # 声明分表的节点数量
              sharding-count: 2

        # 选择使用内置的雪花算法
        key-generators:
          global-id-snowflake:
            # 选择使用内置的雪花算法
            type: SNOWFLAKE
            props:
              # 分配一个工作节点ID（要确保全局唯一）
              worker-id: 111

        # 配置绑定表关系
        binding-tables:
          # 配置第一组绑定表的关系（订单表、订单详情表）
          - order_tab,order_info

        # 配置广播表信息
        broadcast-tables:
          - user_info



# mybatis-plus 配置内容
mybatis-plus:
  configuration:
    map-underscore-to-camel-case: true # 虽然默认为 true ，但是还是显示去指定下。
#    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl #开启sql日志
  global-config:
    db-config:
      id-type: none # 虽然 MyBatis Plus 也提供 ID 生成策略，但是还是使用 Sharding-JDBC 的
      logic-delete-value: 1 # 逻辑已删除值(默认为 1)
      logic-not-delete-value: 0 # 逻辑未删除值(默认为 0)
  mapper-locations: classpath*:mapper/*.xml


