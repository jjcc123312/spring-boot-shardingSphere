logging:
  level:
    com.study: info

spring:
  application:
    name: shardingSphere-sharding-algorithm

  shardingsphere:
    # 将运行模式配置为Standalone单机模式（Cluster：集群模式）
    mode:
      type: Standalone
      repository:
        type: JDBC
    props:
      # 日志显示具体的SQL
      sql-show: true
    # 配置多个数据源
    datasource:
      #      真实数据源名称
      names: ds0,ds1
      #      druid数据库连接池配置
      common: &common
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.jdbc.Driver
        time-between-eviction-runs-millis: 60000
        min-evictable-idle-time-millis: 300000
        max-active: 500
        initial-size: 3
        min-idle: 3
        max-wait: 60000
        remove-abandoned: true
        remove-abandoned-timeout: 300
        log-abandoned: true
      # 配置第一个数据源
      ds0:
        #        引用common配置
        <<: *common
        driver-class-name: com.mysql.jdbc.Driver
        url: jdbc:mysql://localhost:3306/db_sharding_01?useUnicode=true&useSSL=false&characterEncoding=utf8
        username: root
        password: 123456

      # 配置第二个数据源
      ds1:
        # 引用common配置
        <<: *common
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.jdbc.Driver
        url: jdbc:mysql://localhost:3306/db_sharding_02?useUnicode=true&useSSL=false&characterEncoding=utf8
        username: root
        password: 123456

    rules:
      sharding:
        tables:
          volume_range:
            actual-data-nodes: ds0.volume_range_$->{0..3}
            key-generate-strategy:
              column: order_id
              key-generator-name: global-id-snowflake
#            database-strategy:
#              standard:
#                sharding-column: order_id
#                sharding-algorithm-name: key-int-mod
            table-strategy:
              standard:
                sharding-column: order_price
                # 分片容量的范围分片算法
                sharding-algorithm-name: volume-range-algorithm
          boundary_range:
            actual-data-nodes: ds0.boundary_range$->{0..3}
            key-generate-strategy:
              column: order_id
              key-generator-name: global-id-snowflake
            table-strategy:
              standard:
                sharding-column: order_price
                # 分片边界的范围分片算法
                sharding-algorithm-name: boundary-range-algorithm

        sharding-algorithms:
          # 取模分片算法
          key-int-mod:
            type: MOD
            props:
              sharding-count: 2
          # 基于分片容量的范围分片算法
          volume-range-algorithm:
            type: VOLUME_RANGE
            props:
              # 范围下界
              range-lower: 0
              # 范围上界
              range-upper: 81
              # 每个分片的容量；每个分片容量最多 = (range-upper -1) / (单个库逻辑表的数量 - 1)
              sharding-volume: 27
          # 基于分片边界的范围分片算法
          boundary-range-algorithm:
            type: BOUNDARY_RANGE
            props:
              sharding-ranges: 0,10,20

        key-generators:
          global-id-snowflake:
            type: SNOWFLAKE
            props:
              # 分配一个工作节点ID（要确保全局唯一）
              worker-id: 112


# mybatis-plus 配置内容
mybatis-plus:
  configuration:
    map-underscore-to-camel-case: true # 虽然默认为 true ，但是还是显示去指定下。
  #    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl #开启sql日志
  global-config:
    db-config:
      id-type: none # 虽然 MyBatis Plus 也提供 ID 生成策略，但是还是使用 Sharding-JDBC 的
      logic-delete-value: 1 # 逻辑已删除值(默认为 1)
      logic-not-delete-value: 0 # 逻辑未删除值(默认为 0)
  mapper-locations: classpath*:mapper/*.xml